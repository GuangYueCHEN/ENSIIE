---
title: "PROJET_IAS"
author: "LI _Ziheng"
date: "2019/2/11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=TRUE}
train <- read.csv(file = './rossmann-store-sales/train.csv', header = TRUE)
store <- read.csv(file = './rossmann-store-sales/store.csv', header = TRUE)
```


```{r, include=TRUE}
library(dplyr)
data <- left_join(train, store, by = c("Store" = "Store"))
DataSet <- data[,-c(1, 3, 5, 13, 14, 16, 17, 18)]
```

```{r, include=TRUE}
DataSet <- na.omit(DataSet)
quantile <- quantile(DataSet$CompetitionDistance, 0.98)
DataSet$CompetitionDistance[DataSet$CompetitionDistance > quantile] <- quantile
```

```{r, include=TRUE}
DataSet$CompetitionDistance <- scale(DataSet$CompetitionDistance, center = FALSE, scale = TRUE)
hist(DataSet$CompetitionDistance)
```

```{r, include=TRUE}
library(data.table)
library(mltools)
DataSet$DayOfWeek <- as.factor(DataSet$DayOfWeek)
DataSet <- one_hot(as.data.table(DataSet))
```

```{r, include=TRUE}
library(corrplot)
corr<-cor(DataSet[,c(seq(1,7,1),seq(9,15,1),8)])
corrplot(corr,main="the correlation with date",mar = c(0,0,1,0))
```



```{r, include=TRUE}
corr<-cor(DataSet[,c(seq(16,24),8)])
corrplot(corr,main="the correlation with store",mar = c(0,0,1,0))
```


```{r , include=FALSE,echo=FALSE}
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
  
  return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[1])
  
}

```


#linear model
```{r, include=TRUE}
n <- dim(DataSet)[1]
TrainSize <- round(n*.75)
TrainIndex <- sample(1:n, size = TrainSize)

TrainSet <- DataSet[TrainIndex,]
TestSet <- DataSet[-TrainIndex,]

```

```{r, include=TRUE}
modTrain = lm(Sales~., data = TrainSet)
pre = predict.lm(modTrain, newdata = TestSet[,-8])

```
```{r, include=TRUE}
cat("RMSE =", RMSE(pre,TestSet$Sales))



plot(as.matrix(pre[c(seq(1,100))])-TestSet$Sales[c(seq(1,100))],xlab = "index ",ylab="bias error",ylim=c(-10000,10000) )
abline(h=0)
abline(h=4000)
abline(h=-4000)
```


```{r, include=TRUE}
library(MASS)
library(lars)

 modlasso = lars(x=as.matrix(TrainSet[,-8]),y=as.matrix(TrainSet[,8]),type="lasso")
Y_esti<-predict.lars(modlasso,as.matrix(TrainSet[,-8]),type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
```



```{r, include=TRUE}
cat("RMSE =", RMSE(Y_esti$fit,TestSet$Sales))



plot(as.matrix(Y_esti$fit[c(seq(1,100))])-TestSet$Sales[c(seq(1,100))],xlab = "index ",ylab="bias error",ylim=c(-10000,10000) )
abline(h=0)
abline(h=4000)
abline(h=-4000)
```


```{r, include=TRUE}


 modridge<-lm.ridge(as.matrix(TrainSet[,8])~.,data=TrainSet[,-8],lambda=seq(0,10,0.01))
lambda<-modridge$lambda[which.min(modridge$GCV)]
modridge<-lm.ridge(as.matrix(TrainSet[,8])~.,data=TrainSet[,-8],lambda=lambda)
coef<-coef(modridge)
un<-matrix(1,nrow=dim(as.vector(TestSet))[1],ncol=1)
Y_esti<-cbind(un,as.matrix(TestSet[,-8]))%*%as.vector(coef)
```



```{r, include=TRUE}
cat("RMSE =", RMSE(Y_esti,TestSet$Sales))



plot(as.matrix(Y_esti[c(seq(1,100))])-TestSet$Sales[c(seq(1,100))],xlab = "index ",ylab="bias error",ylim=c(-10000,10000) )
abline(h=0)
abline(h=4000)
abline(h=-4000)
```







































































