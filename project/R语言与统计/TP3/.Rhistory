L_cauchy <- function(X_N, x0, alpha) {
pi <- 3.1415926
return (sum(log(alpha / pi) - log((X_N - x0)**2 + alpha**2)))
}
library(ggplot2)
C_echan<-rcauchy(100,location=-2,scale=0.4)
L_cauchy <- function(X_N, x0, alpha) {
pi <- 3.1415926
return (sum(log(alpha / pi) - log((X_N - x0)**2 + alpha**2)))
}
lambda<-2
L<-4
E_echan<-rexp(100,rate=lambda) * exp(lambda * L)
L_exp <- function(X_N, lambda, L) {
return (sum(log(lambda) - lambda * (X_N - L)))
}
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
n <- 100
m <- 1
x0s            <- rep(seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n)
alphas         <- rep(seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n)
vraissemblance <- c()
gradient       <- c()
n <- 100
m <- 1
x0s            <- rep(seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n)
alphas         <- rep(seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n)
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(cauchy, x0s[i], alphas[i])
# une transformation qui préserve le maximum, mais qui permet d'avoir une meilleure image
gradient[i]       <- exp(vraissemblance[i] * 0.1)
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
n <- 100
m <- 1
x0s            <- rep(seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n)
alphas         <- rep(seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n)
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x0s[i], alphas[i])
# une transformation qui préserve le maximum, mais qui permet d'avoir une meilleure image
gradient[i]       <- exp(vraissemblance[i] * 0.1)
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x0s, alphas, vraissemblance, gradient)
ggplot(df, aes(x0s, alphas)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(4))
# vrais paramètres
c("x0" = x0, "alpha_max" = alpha)
n <- 100
m <- 1
x0s            <- rep(seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n)
alphas         <- rep(seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n)
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x0s[i], alphas[i])
# une transformation qui préserve le maximum, mais qui permet d'avoir une meilleure image
gradient[i]       <- exp(vraissemblance[i] * 0.1)
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x0s, alphas, vraissemblance, gradient)
ggplot(df, aes(x0s, alphas)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(4))
# vrais paramètres
c("x0" = -2, "alpha_max" = alpha)
# valeurs des paramètres pour lesquels la vraissemblance est maximal:
c("x0_max" = x0s[m], "alpha_max" = alphas[m])
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alphas         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alphas[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
ggplot(df, aes(x, alphas)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn()
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alphas         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alphas[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
ggplot(df, aes(x, alphas)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = 4)
c("x0" = -2, "alpha_max" = alpha)
c("x0_max" = x0s[m], "alpha_max" = alphas[m])
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alphas         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alphas[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
ggplot(df, aes(x, alphas)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
c("x0" = -2, "alpha_max" = alpha)
c("x0_max" = x0s[m], "alpha_max" = alphas[m])
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
c("x0" = -2, "alpha_max" = alpha)
c("x0_max" = x[m], "alpha_max" = alphas[m])
library(ggplot2)
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
c("x0" = -2, "alpha_max" = alpha)
c("x0_max" = x[m], "alpha_max" = alphas[m])
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
N <- 10
p <- 0.7
Ber_echan <- rbinom(N, 1,prob=p)
mean(Ber_echan)
L_bern<-function(echan, p){
res <- 1
for (i in echan){
res <- res * (p**i * (1-p)**(1-i))
}
return(res)
}
Ber_courbe<-function(N){
p <- seq(0, 1, 1/N)
L <- vector(length = length(p))
for(i in 1:length(p)){
L[i]=L_bern( Ber_echan ,p[i] )
}
plot(L,x=p,ylab="vraisemblance")
}
Ber_courbe(100)
x<-optimize(L_bern, echan=Ber_echan, interval=c(0,1), maximum=TRUE)
N <-seq(10,2000,10)
res=vector(length = length(N))
for(k in 1:length(N) ){
xx=rbinom(N[k], 1 ,0.7)
pk=optimize(L_bern, echan=xx, interval=c(0,1), maximum=TRUE)
res[k]=pk$maximum
}
plot(y= res,x=N)
mean(res[1:120])
N<-read.csv("distribution_inconue_2_100_realisations.csv",header = TRUE)["x"]
x=as.vector(as.matrix(N))
optimize(L_bern, echan=x, interval=c(0,1), maximum=TRUE)
N <- 30
mu= 2
delta = 1
N_echan <- rnorm(N, mu ,delta)
print(N_echan)
L_norm<-function(echan,mu){
som<-0
for (i in echan) {
som<-som+(i-mu)**2
}
res<-(2*pi)**(-length(echan)/2)*exp(-0.5*som)
return(res)
}
L_norm(N_echan,2)
log_L_norm <- function(X_N, mu) {
#return (prod(dnorm(X_N, mu, 1)))
return (sum(log(dnorm(X_N, mu, 1))))
}
for (i in 1:length(N)) {
X_Ni  <- rnorm(N[i], 2, 1)
mu   <- optimize(function(mu) { log_L_norm(X_Ni, mu) }, interval=c(0,4), maximum=TRUE)
res[i] <- mu$maximum
}
plot(N, res)
N <-seq(10,2000,10)
res=vector(length = length(N))
for(k in 1:length(N) ){
xx=rbinom(N[k], 1 ,0.7)
pk=optimize(L_bern, echan=xx, interval=c(0,1), maximum=TRUE)
res[k]=pk$maximum
}
plot(y= res,x=N)
mean(res[1:120])
log_L_norm <- function(X_N, mu) {
#return (prod(dnorm(X_N, mu, 1)))
return (sum(log(dnorm(X_N, mu, 1))))
}
for (i in 1:length(N)) {
X_Ni  <- rnorm(N[i], 2, 1)
mu   <- optimize(function(mu) { log_L_norm(X_Ni, mu) }, interval=c(0,4), maximum=TRUE)
res[i] <- mu$maximum
}
plot(N, res)
mean(res)
C_echan<-rcauchy(100,location=-2,scale=0.4)
L_cauchy <- function(X_N, x0, alpha) {
pi <- 3.1415926
return (sum(log(alpha / pi) - log((X_N - x0)**2 + alpha**2)))
}
lambda<-2
L<-4
E_echan<-rexp(100,rate=lambda) * exp(lambda * L)
L_exp <- function(X_N, lambda, L) {
return (sum(log(lambda) - lambda * (X_N - L)))
}
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
library(ggplot2)
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alphas, vraissemblance, gradient)
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alpha, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
c("x0" = -2, "alpha" = alpha)
c("x0_max" = x[m], "alpha_max" = alphas[m])
C_echan<-rcauchy(100,location=-2,scale=0.4)
L_cauchy <- function(X_N, x0, alpha) {
pi <- 3.1415926
return (sum(log(alpha / pi) - log((X_N - x0)**2 + alpha**2)))
}
echan=matrix(rnorm(5*1000,1,2),nrow=5);
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
；；
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan<-matrix(rnorm(5*1000,1,2),nrow=5);
}
N <- 10
p <- 0.7
Ber_echan <- rbinom(N, 1,prob=p)
mean(Ber_echan)
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alpha, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
c("x0" = -2, "alpha" = 0.4)
c("x0_max" = x[m], "alpha_max" = alpha[m])
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alpha, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
print("x0" = -2, "alpha" = 0.4)
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alpha, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
x0=-2
alpha=0.4
c("x0_max" = x[m], "alpha_max" = alpha[m])
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
L_norm<-function(echan,mu){
som<-0
for (i in echan) {
som<-som+(i-mu)**2
}
res<-(2*pi)**(-length(echan)/2)*exp(-0.5*som)
return(res)
}
L_norm(N_echan,2)
knitr::opts_chunk$set(echo = TRUE)
function(n){
echan=matrix(rnorm(5*1000,1,2),nrow=5);
}
N <- 10
p <- 0.7
Ber_echan <- rbinom(N, 1,prob=p)
mean(Ber_echan)
L_bern<-function(echan, p){
res <- 1
for (i in echan){
res <- res * (p**i * (1-p)**(1-i))
}
return(res)
}
Ber_courbe<-function(N){
p <- seq(0, 1, 1/N)
L <- vector(length = length(p))
for(i in 1:length(p)){
L[i]=L_bern( Ber_echan ,p[i] )
}
plot(L,x=p,ylab="vraisemblance")
}
Ber_courbe(100)
x<-optimize(L_bern, echan=Ber_echan, interval=c(0,1), maximum=TRUE)
N <-seq(10,2000,10)
res=vector(length = length(N))
for(k in 1:length(N) ){
xx=rbinom(N[k], 1 ,0.7)
pk=optimize(L_bern, echan=xx, interval=c(0,1), maximum=TRUE)
res[k]=pk$maximum
}
plot(y= res,x=N)
mean(res[1:120])
N<-read.csv("distribution_inconue_2_100_realisations.csv",header = TRUE)["x"]
x=as.vector(as.matrix(N))
optimize(L_bern, echan=x, interval=c(0,1), maximum=TRUE)
N <- 30
mu= 2
delta = 1
N_echan <- rnorm(N, mu ,delta)
print(N_echan)
L_norm<-function(echan,mu){
som<-0
for (i in echan) {
som<-som+(i-mu)**2
}
res<-(2*pi)**(-length(echan)/2)*exp(-0.5*som)
return(res)
}
L_norm(N_echan,2)
N_courbe<-function(n){
mux=seq(0,4,0.04)
Ne <- vector(length =length(mux))
for(i in 1:100){
Ne[i]=L_norm( N_echan , mux[i] )
}
plot(y=Ne,x=mux,ylab="vraisemblance")
}
N_courbe(100)
x<-optimize(L_norm, echan=N_echan, interval=c(0,4), maximum=TRUE)
x
N <-seq(10,2000,10)
res=vector(length = length(N))
for(k in 1:length(N) ){
xx=rnorm(N[k], mu ,delta)
pk=optimize(L_norm, echan=xx, interval=c(0,4), maximum=TRUE)
res[k]=pk$maximum
}
plot(y= res,x=N)
mean(res[100:200])
log_L_norm <- function(X_N, mu) {
#return (prod(dnorm(X_N, mu, 1)))
return (sum(log(dnorm(X_N, mu, 1))))
}
for (i in 1:length(N)) {
X_Ni  <- rnorm(N[i], 2, 1)
mu   <- optimize(function(mu) { log_L_norm(X_Ni, mu) }, interval=c(0,4), maximum=TRUE)
res[i] <- mu$maximum
}
plot(N, res)
mean(res)
library(stats4)
lambda<-2
L<-4
E_echan<-rexp(100,rate=lambda) * exp(lambda * L)
L_exp <- function(X_N, lambda, L) {
return (sum(log(lambda) - lambda * (X_N - L)))
}
C_echan<-rcauchy(100,location=-2,scale=0.4)
L_cauchy <- function(X_N, x0, alpha) {
pi <- 3.1415926
return (sum(log(alpha / pi) - log((X_N - x0)**2 + alpha**2)))
}
library(ggplot2)
n <- 100
m <- 1
x            <- rep( seq(-4.0, 0.0, (0.0 - -4.0) / (n - 1)), times=n  )
alpha         <- rep( seq(0.0, 1.0, (1.0 - 0.0) / (n - 1)), each=n  )
vraissemblance <- c()
gradient       <- c()
for (i in 1:(n*n)) {
vraissemblance[i] <- L_cauchy(C_echan, x[i], alpha[i])
gradient[i]       <- exp( vraissemblance[i] * 0.1 )
m <- if (vraissemblance[i] > vraissemblance[m]) i else m
}
df <- data.frame(x, alpha, vraissemblance, gradient)
ggplot(df, aes(x, alpha)) +
geom_raster(aes(fill = gradient)) +
scale_fill_gradientn(colours = topo.colors(5))
c("x0" = -2, "alpha" = 0.4)
c("x0_max" = x[m], "alpha_max" = alpha[m])
