ASP<-as.matrix(data[108])
ACC<-as.matrix(data[109])
reg1<-lm(ASP~X)
summary(reg1)
reg2<-lm(ACC~X)
summary(reg2)
y_esti<-predict.lm(reg1,data=X)
#for cross validation, we compute the RMSE
X<-as.matrix(data[c(seq(1,107,1))])
ASP<-as.matrix(data[108])
ACC<-as.matrix(data[109])
reg1<-lm(ASP~X)
summary(reg1)
reg2<-lm(ACC~X)
summary(reg2)
y_esti<-predict.lm(reg1,data=X)
RMSE(y_esti,ASP)
help(predict.lm)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(c(1,1,1,1,1,1,1,1,1,1,1,1,1),c(1,1,1,1,1,1,1,1,1,1,1,1,1))
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[0])
}
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[1])
}
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
BIC(reg1)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
BIC(reg1)
BIC(reg2)
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[1])
}
Non_biased_residual<-function(Y_esti,Y){
sum=0
p=length(Y)
for(i in seq(1,length(Y))){
sum<-sum+(Y_esti[i]-Y[i])^2
}
NBR<- sqrt(sum/(length(Y)-p+1))
return(NBR)
}
#for cross validation, we compute the RMSE
X<-as.matrix(data[c(seq(1,107,1))])
ASP<-as.matrix(data[108])
ACC<-as.matrix(data[109])
reg1<-lm(ASP~X)
summary(reg1)
reg2<-lm(ACC~X)
summary(reg2)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
Non_biased_residual(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
BIC(reg1)
BIC(reg2)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
Non_biased_residual(y_esti,ASP,107)
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[1])
}
Non_biased_residual<-function(Y_esti,Y,p){
sum=0
for(i in seq(1,length(Y))){
sum<-sum+(Y_esti[i]-Y[i])^2
}
NBR<- sqrt(sum/(length(Y)-p+1))
return(NBR)
}
y_esti<-predict.lm(reg1,data=X,level = 0.95)
Non_biased_residual(y_esti,ASP,107)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
BIC(reg1)
BIC(reg2)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
Non_biased_residual(y_esti,ASP,107)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
Non_biased_residual(y_esti,ACC,107)
BIC(reg1)
BIC(reg2)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
Non_biased_residual(y_esti,ASP,107)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
BIC(reg1)
BIC(reg2)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
BIC(reg1)
BIC(reg2)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
regbic = step(reg1, direction = 'both', k = log(nrow(X)))
BIC(reg1)
BIC(reg2)
BIC(regbic)
y_esti<-predict.lm(reg1,data=X,level = 0.95)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level = 0.95)
RMSE(y_esti,ACC)
regbic = step(reg1, direction = 'both', k = log(nrow(X)))
regbic2 = step(reg2, direction = 'both', k = log(nrow(X)))
BIC(reg1)
BIC(reg2)
BIC(regbic)
BIC(regbic2)
y_esti<-predict.lm(reg1,data=X,level =1)
RMSE(y_esti,ASP)
y_esti<-predict.lm(reg2,data=X,level =1)
RMSE(y_esti,ACC)
regbic = step(reg1, direction = 'both', k = log(nrow(X)))
regbic2 = step(reg2, direction = 'both', k = log(nrow(X)))
BIC(reg1)
BIC(reg2)
BIC(regbic)
BIC(regbic2)
help(predict.ridge)
modlasso = lars(x=X,y=ASP,type="lasso")
require(corrplot)
require(gdata)
library(MASS)
library(lars)
install.packages(lars)
install.packages("lars")
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
modridge<-lm.ridge(ASP~.,data=X,lambda=lambda)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
modridge<-lm.ridge(ASP~.,data=data[c(sea(1,108,1))],lambda=lambda)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=lambda)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=seq(0,10,0.01))
lambda<-modridge$lambda[which.min(modridge$GCV)]
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=lambda)
coef<-coef(modridge)
un<-matrix(1,nrow=length(ASP),ncol=1)
Y_esti<-cbind(un,X)%*%as.vector(coef)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
RMSE(y_esti,ASP)
BIC(modlasso)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
RMSE(y_esti,ASP)
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=seq(0,10,0.01))
lambda<-modridge$lambda[which.min(modridge$GCV)]
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=lambda)
coef<-coef(modridge)
un<-matrix(1,nrow=length(ASP),ncol=1)
Y_esti<-cbind(un,X)%*%as.vector(coef)
RMSE(y_esti,ASP)
BIC(modridge)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
RMSE(y_esti,ASP)
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=seq(0,10,0.01))
lambda<-modridge$lambda[which.min(modridge$GCV)]
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=lambda)
coef<-coef(modridge)
un<-matrix(1,nrow=length(ASP),ncol=1)
Y_esti<-cbind(un,X)%*%as.vector(coef)
RMSE(y_esti,ASP)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
RMSE(Y_esti,ASP)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
RMSE(as.matrix(Y_esti),ASP)
View(Y_esti)
library(MASS)
library(lars)
modlasso = lars(x=X,y=ASP,type="lasso")
Y_esti<-predict.lars(modlasso,X,type="fit",mode="lambda",s=modlasso$lambda[which.min(modlasso$RSS)-1])
RMSE(as.matrix(Y_esti$fit),ASP)
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=seq(0,10,0.01))
lambda<-modridge$lambda[which.min(modridge$GCV)]
modridge<-lm.ridge(ASP~.,data=data[c(seq(1,108,1))],lambda=lambda)
coef<-coef(modridge)
un<-matrix(1,nrow=length(ASP),ncol=1)
Y_esti<-cbind(un,X)%*%as.vector(coef)
RMSE(as.matrix(Y_esti),ASP)
cv1 <- cv.glmnet(X, ASP, family = "binomial", nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 1)
library(glmnet)
cv1 <- cv.glmnet(X, ASP, family = "binomial", nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 1)
library(glmnet)
cv1 <- cv.glmnet(X, ASP,nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 1)
md1 <- glmnet(X, ASP, lambda = cv1$lambda.1se, alpha = 1)
coef(md1)
library(glmnet)
cv1 <- cv.glmnet(X, ASP,nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 1)
md1 <- glmnet(X, ASP, lambda = cv1$lambda.1se, alpha = 1)
coef(md1)
RMSE(as.numeric(predict(md1,X, type = "response")),ASP)
library(glmnet)
cv1 <- cv.glmnet(X, ASP,nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 0)
md1 <- glmnet(X, ASP, lambda = cv1$lambda.1se, alpha = 0)
coef(md1)
RMSE(as.numeric(predict(md1,X, type = "response")),ASP)
library(glmnet)
cv1 <- cv.glmnet(X, ASP,nfold = 10, paralle = TRUE, alpha = 0)
md1 <- glmnet(X, ASP, lambda = cv1$lambda.1se, alpha = 0)
coef(md1)
RMSE(as.numeric(predict(md1,X, type = "response")),ASP)
library(glmnet)
cv1 <- cv.glmnet(X, ASP,nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 0)
md1 <- glmnet(X, ASP, lambda = cv1$lambda.1se, alpha = 0)
coef(md1)
plot(cvl)
library(elastic)
library(elastic)
library(elastic.net)
beta <- rep(c(0,1,0,-1,0), c(25,10,25,10,25))
labels <- rep("irrelevant", length(beta))
plot(elastic.net(X,ASP,lambda2=0), label=labels) ## a mess
library(glmnet)
beta <- rep(c(0,1,0,-1,0), c(25,10,25,10,25))
labels <- rep("irrelevant", length(beta))
plot(elastic.net(X,ASP,lambda2=0), label=labels) ## a mess
help("elastic.net")
??elastic.net
library(quadrupen)
beta <- rep(c(0,1,0,-1,0), c(25,10,25,10,25))
labels <- rep("irrelevant", length(beta))
plot(elastic.net(X,ASP,lambda2=0), label=labels) ## a mess
plot(elastic.net(X,ASP,lambda2=10), label=labels)
library(quadrupen)
plot(elastic.net(X,ASP,lambda2=0)) ## a mess
plot(elastic.net(X,ASP,lambda2=10))
library(quadrupen)
elastic.net(X,ASP,lambda2=0) ## a mess
plot(elastic.net(X,ASP,lambda2=10))
library(quadrupen)
plot(elastic.net(X,ASP,lambda2=0)) ## a mess
library(quadrupen)
elastic.net(X,ASP,lambda2=0)
library(quadrupen)
mod_net<-elastic.net(X,ASP,lambda2=0)
View(mod_net)
View(modridge)
library(quadrupen)
mod_net<-elastic.net(X,ASP,lambda2=seq(0,10,0.01))
View(mod_net)
library(quadrupen)
for (lambda in seq(0,10,0.01)){
mod_net<-elastic.net(X,ASP,lambda2=lambda)
coef<-coef(mod_net)
un<-matrix(1,nrow=length(ASP),ncol=1)
Y_esti<-cbind(un,X)%*%as.vector(coef)
RMSE(as.matrix(Y_esti),ASP)
}
#library(quadrupen)
#plot(elastic.net(X,ASP,lambda2=0)) ## a mess
#plot(elastic.net(X,ASP,lambda2=10))
ind<-sample(3,nrow(VietNamI_reduced),replace=T,prob = c(0.5,0.25,0.25))
#library(quadrupen)
#plot(elastic.net(X,ASP,lambda2=0)) ## a mess
#plot(elastic.net(X,ASP,lambda2=10))
ind<-sample(3,nrow(X),replace=T,prob = c(0.5,0.25,0.25))
train<-VietNamI_reduced[ind==1,]
#library(quadrupen)
#plot(elastic.net(X,ASP,lambda2=0)) ## a mess
#plot(elastic.net(X,ASP,lambda2=10))
ind<-sample(3,nrow(data),replace=T,prob = c(0.5,0.25,0.25))
train<-data[ind==1,]
cross<-data[ind==2,]
test<-data[ind==3,]
#library(quadrupen)
#plot(elastic.net(X,ASP,lambda2=0)) ## a mess
#plot(elastic.net(X,ASP,lambda2=10))
ind<-sample(3,nrow(data),replace=T,prob = c(0.5,0.25,0.25))
require(corrplot)
require(gdata)
data = read.xls ("/home/guangyue.chen/S3/MRR/projet/residential/Residential-Building-Data-Set.xlsx", sheet = 1, header = TRUE)
#library(quadrupen)
#plot(elastic.net(X,ASP,lambda2=0)) ## a mess
#plot(elastic.net(X,ASP,lambda2=10))
ind<-sample(3,nrow(data),replace=T,prob = c(0.5,0.25,0.25))
train<-data[ind==1,]
cross<-data[ind==2,]
test<-data[ind==3,]
#library(quadrupen)
#plot(elastic.net(X,ASP,lambda2=0)) ## a mess
#plot(elastic.net(X,ASP,lambda2=10))
ind<-sample(3,nrow(data),replace=T,prob = c(0.5,0.25,0.25))
train<-data[ind==1,]
cross<-data[ind==2,]
test<-data[ind==3,]
trainX<-as.matrix(train[c(seq(1,107,1))])
trainASP<-as.matrix(train[108])
trainACC<-as.matrix(train[109])
crossX<-as.matrix(cross[c(seq(1,107,1))])
crossASP<-as.matrix(cross[108])
crossACC<-as.matrix(cross[109])
testX<-as.matrix(test[c(seq(1,107,1))])
testASP<-as.matrix(test[108])
testACC<-as.matrix(test[109])
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[1])
}
help("CVlm")
library(DAAG)
install.packages(DAAG)
library("DAAG")
install.packages("DAAG")
#for cross validation, we compute the RMSE
X<-as.matrix(data[c(seq(1,107,1))])
ASP<-as.matrix(data[108])
ACC<-as.matrix(data[109])
reg1<-lm(ASP~X)
summary(reg1)
reg2<-lm(ACC~X)
summary(reg2)
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(df=ASP, form.lm=ASP ~ X, m=5, dots=FALSE, seed=29, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
help("CVlm")
require(corrplot)
require(gdata)
data = read.xls ("/home/guangyue.chen/S3/MRR/projet/residential/Residential-Building-Data-Set.xlsx", sheet = 1, header = TRUE)
#for cross validation, we compute the RMSE
X<-data[c(seq(1,107,1))]
ASP<-data[108]
ACC<-data[109]
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(df=ASP, form.lm=ASP ~ X, m=5, dots=FALSE, seed=29, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=ASP ~ X, m=5, dots=FALSE, seed=29, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=as.matrix(ASP) ~ X, m=5, dots=FALSE, seed=29, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=as.matrix(ASP) ~ as.matrix(X), m=5, dots=FALSE, seed=29, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=as.matrix(ASP) ~ as.matrix(X), m=5, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=as.matrix(ASP) ~ as.matrix(X), m=6, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=6, legend.pos="topleft",  printit=FALSE, main="Small symbols are predicted values while bigger ones are actuals."));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=3, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(data, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=3, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=3, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=1, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, we compute the RMSE
RMSE<-function(y_esti,y){
return(sqrt(t(y_esti-y)%*%(y_esti-y)/length(y))[1])
}
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
cvResults <- suppressWarnings(CVlm(X, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=1, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
X<-data[c(seq(1,108,1))]
ASP<-data[108]
cvResults <- suppressWarnings(CVlm(X, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=1, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(CVlm(data1, form.lm=formula(as.matrix(ASP) ~ as.matrix(X)), m=1, legend.pos="topleft",  printit=FALSE, main="Small symbols show cross-validation predicted values"));
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(df = houseprices, form.lm = formula(sale.price ~ area), m=3, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(data = houseprices, form.lm = formula(sale.price ~ area), m=3, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
# performs the CV
attr(cvResults, 'ms')
view(houseprices)
head(houseprices)
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(data =data1, form.lm = formula(ASP ~ .), m=3, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
# performs the CV
attr(cvResults, 'ms')
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(data =data1, form.lm = formula(ASP ~ .), m=5, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
# performs the CV
attr(cvResults, 'ms')
which.min(RMSE())
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(data =data1, form.lm = formula(ASP ~ .), m=5, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
# performs the CV
attr(cvResults, 'ms')
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(data =data1, form.lm = formula(ASP ~ .), m=10, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
# performs the CV
attr(cvResults, 'ms')
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <- suppressWarnings(
CVlm(data =data1, form.lm = formula(ASP ~ .), m=10, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
);
# performs the CV
attr(cvResults, 'ms')
which.min(Mean square)
which.min(RMSE(cvResults$Predicted,as.matrix(ASP)))
cvResults$Predicted
View(cvResults)
#for cross validation, slice the data into three parts, train , cross, test
library(DAAG)
data1<-data[c(seq(1,108,1))]
X<-data[c(seq(1,107,1))]
ASP<-data[108]
cvResults <-
CVlm(data =data1, form.lm = formula(ASP ~ .), m=10, dots =FALSE, seed=29, plotit=TRUE, printit=TRUE)
# performs the CV
attr(cvResults, 'ms')
which.min(cvResults$Predicted)
